---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-compactor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "compactor"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "compactor"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-distributor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "distributor"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "distributor"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-ingester
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "ingester"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "ingester"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-querier
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "querier"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "querier"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-query-frontend
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-frontend"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "query-frontend"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-query-scheduler
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-scheduler"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "query-scheduler"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: pyroscope-dev-store-gateway
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "store-gateway"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "store-gateway"
---
# Source: pyroscope/charts/alloy/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pyroscope-dev-alloy
  namespace: default
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
---
# Source: pyroscope/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "minio-sa"
  namespace: "default"
---
# Source: pyroscope/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pyroscope-dev
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: pyroscope/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: pyroscope-dev-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
type: Opaque
data:
  rootUser: "Z3JhZmFuYS1weXJvc2NvcGU="
  rootPassword: "c3VwZXJzZWNyZXQ="
---
# Source: pyroscope/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: pyroscope-dev-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
      OBJECTLOCKING=$5
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
    # Create the bucket if it does not exist and set objectlocking if enabled (NOTE: versioning will be not changed if OBJECTLOCKING is set because it enables versioning to the Buckets created)
    if ! checkBucketExists $BUCKET ; then
        if [ ! -z $OBJECTLOCKING ] ; then
          if [ $OBJECTLOCKING = true ] ; then
              echo "Creating bucket with OBJECTLOCKING '$BUCKET'"
              ${MC} mb --with-lock myminio/$BUCKET
          elif [ $OBJECTLOCKING = false ] ; then
                echo "Creating bucket '$BUCKET'"
                ${MC} mb myminio/$BUCKET
          fi
      elif [ -z $OBJECTLOCKING ] ; then
            echo "Creating bucket '$BUCKET'"
            ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."  
      fi
      fi
    
    
      # set versioning for bucket if objectlocking is disabled or not set
      if [ -z $OBJECTLOCKING ] ; then
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
    
    # Create the buckets
    createBucket grafana-pyroscope-data none false  
  add-user: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # AccessKey and secretkey credentials file are added to prevent shell execution errors caused by special characters.
    # Special characters for example : ',",<,>,{,}
    MINIO_ACCESSKEY_SECRETKEY_TMP="/tmp/accessKey_and_secretKey_tmp"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkUserExists ()
    # Check if the user exists, by using the exit code of `mc admin user info`
    checkUserExists() {
      CMD=$(${MC} admin user info myminio $(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP) > /dev/null 2>&1)
      return $?
    }
    
    # createUser ($policy)
    createUser() {
      POLICY=$1
      #check accessKey_and_secretKey_tmp file
      if [[ ! -f $MINIO_ACCESSKEY_SECRETKEY_TMP ]];then
        echo "credentials file does not exist"
        return 1
      fi
      if [[ $(cat $MINIO_ACCESSKEY_SECRETKEY_TMP|wc -l) -ne 2 ]];then
        echo "credentials file is invalid"
        rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
        return 1
      fi
      USER=$(head -1 $MINIO_ACCESSKEY_SECRETKEY_TMP)
      # Create the user if it does not exist
      if ! checkUserExists ; then
        echo "Creating user '$USER'"
        cat $MINIO_ACCESSKEY_SECRETKEY_TMP | ${MC} admin user add myminio
      else
        echo "User '$USER' already exists."
      fi
      #clean up credentials files.
      rm -f $MINIO_ACCESSKEY_SECRETKEY_TMP
    
      # set policy for user
      if [ ! -z $POLICY -a $POLICY != " " ] ; then
          echo "Adding policy '$POLICY' for '$USER'"
          ${MC} admin policy set myminio $POLICY user=$USER
      else
          echo "User '$USER' has no policy attached."
      fi
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
    
    # Create the users
    echo console > $MINIO_ACCESSKEY_SECRETKEY_TMP
    echo console123 >> $MINIO_ACCESSKEY_SECRETKEY_TMP
    createUser consoleAdmin
    
  add-policy: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkPolicyExists ($policy)
    # Check if the policy exists, by using the exit code of `mc admin policy info`
    checkPolicyExists() {
      POLICY=$1
      CMD=$(${MC} admin policy info myminio $POLICY > /dev/null 2>&1)
      return $?
    }
    
    # createPolicy($name, $filename)
    createPolicy () {
      NAME=$1
      FILENAME=$2
    
      # Create the name if it does not exist
      echo "Checking policy: $NAME (in /config/$FILENAME.json)"
      if ! checkPolicyExists $NAME ; then
        echo "Creating policy '$NAME'"
      else
        echo "Policy '$NAME' already exists."
      fi
      ${MC} admin policy add myminio $NAME /config/$FILENAME.json
    
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
    
    
  custom-command: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for MinIO service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/rootUser) ; SECRET=$(cat /config/rootPassword) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to MinIO server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} alias set myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # runCommand ($@)
    # Run custom mc command
    runCommand() {
      ${MC} "$@"
      return $?
    }
    
    # Try connecting to MinIO instance
    scheme=http
    connectToMinio $scheme
---
# Source: pyroscope/templates/configmap-alloy.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alloy-config-pyroscope
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
data:
  config.alloy: |
    logging {
    	level  = "info"
    	format = "logfmt"
    }

    discovery.kubernetes "pyroscope_kubernetes" {
    	role = "pod"
    }

    // The default scrape config allows to define annotations based scraping.
    //
    // For example the following annotations:
    //
    // ```
    // profiles.grafana.com/memory.scrape: "true"
    // profiles.grafana.com/memory.port: "8080"
    // profiles.grafana.com/cpu.scrape: "true"
    // profiles.grafana.com/cpu.port: "8080"
    // profiles.grafana.com/goroutine.scrape: "true"
    // profiles.grafana.com/goroutine.port: "8080"
    // ```
    //
    // will scrape the `memory`, `cpu` and `goroutine` profiles from the `8080` port of the pod.
    //
    // For more information see https://grafana.com/docs/pyroscope/latest/deploy-kubernetes/helm/#optional-scrape-your-own-workloads-profiles
    discovery.relabel "kubernetes_pods" {
    	targets = concat(discovery.kubernetes.pyroscope_kubernetes.targets)

    	rule {
    		action        = "drop"
    		source_labels = ["__meta_kubernetes_pod_phase"]
    		regex         = "Pending|Succeeded|Failed|Completed"
    	}

    	rule {
    		action = "labelmap"
    		regex  = "__meta_kubernetes_pod_label_(.+)"
    	}

    	rule {
    		action        = "replace"
    		source_labels = ["__meta_kubernetes_namespace"]
    		target_label  = "namespace"
    	}

    	rule {
    		action        = "replace"
    		source_labels = ["__meta_kubernetes_pod_name"]
    		target_label  = "pod"
    	}

    	rule {
    		action        = "replace"
    		source_labels = ["__meta_kubernetes_pod_container_name"]
    		target_label  = "container"
    	}
    }

    discovery.relabel "kubernetes_pods_memory_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_memory_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_memory_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_memory" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_memory_default_name.output, discovery.relabel.kubernetes_pods_memory_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = true
    		}

    		profile.process_cpu {
    			enabled = false
    		}

    		profile.goroutine {
    			enabled = false
    		}

    		profile.block {
    			enabled = false
    		}

    		profile.mutex {
    			enabled = false
    		}

    		profile.fgprof {
    			enabled = false
    		}
    	}
    }

    discovery.relabel "kubernetes_pods_cpu_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_cpu_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_cpu_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_cpu" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_cpu_default_name.output, discovery.relabel.kubernetes_pods_cpu_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = false
    		}

    		profile.process_cpu {
    			enabled = true
    		}

    		profile.goroutine {
    			enabled = false
    		}

    		profile.block {
    			enabled = false
    		}

    		profile.mutex {
    			enabled = false
    		}

    		profile.fgprof {
    			enabled = false
    		}
    	}
    }

    discovery.relabel "kubernetes_pods_goroutine_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_goroutine_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_goroutine_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_goroutine" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_goroutine_default_name.output, discovery.relabel.kubernetes_pods_goroutine_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = false
    		}

    		profile.process_cpu {
    			enabled = false
    		}

    		profile.goroutine {
    			enabled = true
    		}

    		profile.block {
    			enabled = false
    		}

    		profile.mutex {
    			enabled = false
    		}

    		profile.fgprof {
    			enabled = false
    		}
    	}
    }

    discovery.relabel "kubernetes_pods_block_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_block_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_block_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_block_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_block" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_block_default_name.output, discovery.relabel.kubernetes_pods_block_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = false
    		}

    		profile.process_cpu {
    			enabled = false
    		}

    		profile.goroutine {
    			enabled = false
    		}

    		profile.block {
    			enabled = true
    		}

    		profile.mutex {
    			enabled = false
    		}

    		profile.fgprof {
    			enabled = false
    		}
    	}
    }

    discovery.relabel "kubernetes_pods_mutex_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_mutex_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_mutex_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_mutex" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_mutex_default_name.output, discovery.relabel.kubernetes_pods_mutex_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = false
    		}

    		profile.process_cpu {
    			enabled = false
    		}

    		profile.goroutine {
    			enabled = false
    		}

    		profile.block {
    			enabled = false
    		}

    		profile.mutex {
    			enabled = true
    		}

    		profile.fgprof {
    			enabled = false
    		}
    	}
    }

    discovery.relabel "kubernetes_pods_fgprof_default_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name"]
    		action        = "keep"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_number"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    discovery.relabel "kubernetes_pods_fgprof_custom_name" {
    	targets = concat(discovery.relabel.kubernetes_pods.output)

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scrape"]
    		action        = "keep"
    		regex         = "true"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name"]
    		action        = "drop"
    		regex         = ""
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_container_port_name"]
    		target_label  = "__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port_name"
    		action        = "keepequal"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_scheme"]
    		action        = "replace"
    		regex         = "(https?)"
    		target_label  = "__scheme__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_path"]
    		action        = "replace"
    		regex         = "(.+)"
    		target_label  = "__profile_path__"
    		replacement   = "$1"
    	}

    	rule {
    		source_labels = ["__address__", "__meta_kubernetes_pod_annotation_profiles_grafana_com_fgprof_port"]
    		action        = "replace"
    		regex         = "(.+?)(?::\\d+)?;(\\d+)"
    		target_label  = "__address__"
    		replacement   = "$1:$2"
    	}
    }

    pyroscope.scrape "pyroscope_scrape_fgprof" {
    	clustering {
    		enabled = true
    	}

    	targets    = concat(discovery.relabel.kubernetes_pods_fgprof_default_name.output, discovery.relabel.kubernetes_pods_fgprof_custom_name.output)
    	forward_to = [pyroscope.write.pyroscope_write.receiver]

    	profiling_config {
    		profile.memory {
    			enabled = false
    		}

    		profile.process_cpu {
    			enabled = false
    		}

    		profile.goroutine {
    			enabled = false
    		}

    		profile.block {
    			enabled = false
    		}

    		profile.mutex {
    			enabled = false
    		}

    		profile.fgprof {
    			enabled = true
    		}
    	}
    }

    pyroscope.write "pyroscope_write" {
    	endpoint {
    		url = "http://pyroscope-dev-distributor.default.svc.cluster.local.:4040"
    	}
    }
---
# Source: pyroscope/templates/configmap-overrides.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: pyroscope-dev-overrides-config
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
data:
  overrides.yaml: |
    overrides:
      {}
---
# Source: pyroscope/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: pyroscope-dev-config
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: |
    storage:
      backend: s3
      s3:
        access_key_id: grafana-pyroscope
        bucket_name: grafana-pyroscope-data
        endpoint: pyroscope-dev-minio:9000
        insecure: true
        secret_access_key: supersecret
---
# Source: pyroscope/charts/alloy/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pyroscope-dev-alloy
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
rules:
  # Rules which allow discovery.kubernetes to function.
  - apiGroups:
      - ""
      - "discovery.k8s.io"
      - "networking.k8s.io"
    resources:
      - endpoints
      - endpointslices
      - ingresses
      - nodes
      - nodes/proxy
      - nodes/metrics
      - pods
      - services
    verbs:
      - get
      - list
      - watch
  # Rules which allow loki.source.kubernetes and loki.source.podlogs to work.
  - apiGroups:
      - ""
    resources:
      - pods
      - pods/log
      - namespaces
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "monitoring.grafana.com"
    resources:
      - podlogs
    verbs:
      - get
      - list
      - watch
  # Rules which allow mimir.rules.kubernetes to work.
  - apiGroups: ["monitoring.coreos.com"]
    resources:
      - prometheusrules
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - /metrics
    verbs:
      - get
  # Rules for prometheus.kubernetes.*
  - apiGroups: ["monitoring.coreos.com"]
    resources:
      - podmonitors
      - servicemonitors
      - probes
    verbs:
      - get
      - list
      - watch
  # Rules which allow eventhandler to work.
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - get
      - list
      - watch
  # needed for remote.kubernetes.*
  - apiGroups: [""]
    resources:
      - "configmaps"
      - "secrets"
    verbs:
      - get
      - list
      - watch
  # needed for otelcol.processor.k8sattributes
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
---
# Source: pyroscope/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: default-pyroscope-dev
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  - "discovery.k8s.io"
  resources:
  - pods
  - endpoints
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
---
# Source: pyroscope/charts/alloy/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: pyroscope-dev-alloy
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: pyroscope-dev-alloy
subjects:
  - kind: ServiceAccount
    name: pyroscope-dev-alloy
    namespace: default
---
# Source: pyroscope/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: default-pyroscope-dev
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: default-pyroscope-dev
subjects:
  - kind: ServiceAccount
    name: pyroscope-dev
    namespace: default
---
# Source: pyroscope/charts/alloy/templates/cluster_service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-alloy-cluster
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: networking
spec:
  type: ClusterIP
  clusterIP: 'None'
  selector:
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
  ports:
    # Do not include the -metrics suffix in the port name, otherwise metrics
    # can be double-collected with the non-headless Service if it's also
    # enabled.
    #
    # This service should only be used for clustering, and not metric
    # collection.
    - name: http
      port: 12345
      targetPort: 12345
      protocol: "TCP"
---
# Source: pyroscope/charts/alloy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-alloy
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: networking
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
  internalTrafficPolicy: Cluster
  ports:
    - name: http-metrics
      port: 12345
      targetPort: 12345
      protocol: "TCP"
---
# Source: pyroscope/charts/minio/templates/console-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-minio-console
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9001
      protocol: TCP
      targetPort: 9001
  selector:
    app: minio
    release: pyroscope-dev
---
# Source: pyroscope/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
    monitoring: "true"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: pyroscope-dev
---
# Source: pyroscope/charts/minio/templates/statefulset.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-minio-svc
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: "pyroscope-dev"
    heritage: "Helm"
spec:
  publishNotReadyAddresses: true
  clusterIP: None
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: pyroscope-dev
---
# Source: pyroscope/templates/memberlist-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-memberlist
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: memberlist
      port: 7946
      protocol: TCP
      targetPort: 7946
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    # TODO: Ensure only services that offer memberlist register
    # pyroscope.grafana.com/memberlist: "true"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-compactor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "compactor"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "compactor"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-compactor-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "compactor"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "compactor"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-distributor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "distributor"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "distributor"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-distributor-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "distributor"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "distributor"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-ingester
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "ingester"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "ingester"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-ingester-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "ingester"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "ingester"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-querier
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "querier"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "querier"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-querier-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "querier"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "querier"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-query-frontend
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-frontend"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "query-frontend"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-query-frontend-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-frontend"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "query-frontend"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-query-scheduler
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-scheduler"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "query-scheduler"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-query-scheduler-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-scheduler"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "query-scheduler"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-store-gateway
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "store-gateway"
spec:
  type: ClusterIP
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "store-gateway"
---
# Source: pyroscope/templates/services.yaml
apiVersion: v1
kind: Service
metadata:
  name: pyroscope-dev-store-gateway-headless
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "store-gateway"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 4040
      targetPort: http2
      protocol: TCP
      name: http2
  selector:
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/component: "store-gateway"
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope-dev-distributor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "distributor"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "distributor"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "distributor"
        name: "distributor"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "distributor"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=distributor"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 500m
              memory: 256Mi
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope-dev-querier
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "querier"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "querier"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "querier"
        name: "querier"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "querier"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=querier"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 1
              memory: 256Mi
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope-dev-query-frontend
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-frontend"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "query-frontend"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "query-frontend"
        name: "query-frontend"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "query-frontend"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=query-frontend"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 256Mi
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pyroscope-dev-query-scheduler
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-scheduler"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "query-scheduler"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "query-scheduler"
        name: "query-scheduler"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "query-scheduler"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=query-scheduler"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 256Mi
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pyroscope-dev-distributor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "distributor"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pyroscope-dev-distributor
  minReplicas: 2
  maxReplicas: 3
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
---
# Source: pyroscope/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pyroscope-dev-querier
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "querier"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pyroscope-dev-querier
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 60
  behavior:
    scaleDown: 
      stabilizationWindowSeconds: 60
---
# Source: pyroscope/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pyroscope-dev-query-frontend
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-frontend"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pyroscope-dev-query-frontend
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 60
---
# Source: pyroscope/templates/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: pyroscope-dev-query-scheduler
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "query-scheduler"
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: pyroscope-dev-query-scheduler
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 40
---
# Source: pyroscope/charts/alloy/templates/controllers/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pyroscope-dev-alloy
  labels:
    helm.sh/chart: alloy-0.3.2
    app.kubernetes.io/name: alloy
    app.kubernetes.io/instance: pyroscope-dev
    
    app.kubernetes.io/version: "v1.1.1"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
spec:
  replicas: 1
  podManagementPolicy: Parallel
  minReadySeconds: 10
  serviceName: pyroscope-dev-alloy
  selector:
    matchLabels:
      app.kubernetes.io/name: alloy
      app.kubernetes.io/instance: pyroscope-dev
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: alloy
        profiles.grafana.com/cpu.port_name: http-metrics
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http-metrics
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http-metrics
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: alloy
        app.kubernetes.io/instance: pyroscope-dev
    spec:
      serviceAccountName: pyroscope-dev-alloy
      containers:
        - name: alloy
          image: docker.io/grafana/alloy:v1.1.1
          imagePullPolicy: IfNotPresent
          args:
            - run
            - /etc/alloy/config.alloy
            - --storage.path=/tmp/alloy
            - --server.http.listen-addr=0.0.0.0:12345
            - --server.http.ui-path-prefix=/
            - --cluster.enabled=true
            - --cluster.join-addresses=pyroscope-dev-alloy-cluster
            - --stability.level=public-preview
          env:
            - name: ALLOY_DEPLOY_MODE
              value: "helm"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - containerPort: 12345
              name: http-metrics
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 12345
              scheme: HTTP
            initialDelaySeconds: 10
            timeoutSeconds: 1
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
        - name: config-reloader
          image: ghcr.io/jimmidyson/configmap-reload:v0.12.0
          args:
            - --volume-dir=/etc/alloy
            - --webhook-url=http://localhost:12345/-/reload
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
          resources:
            requests:
              cpu: 1m
              memory: 5Mi
      dnsPolicy: ClusterFirst
      volumes:
        - name: config
          configMap:
            name: alloy-config-pyroscope
---
# Source: pyroscope/charts/minio/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pyroscope-dev-minio
  namespace: "default"
  labels:
    app: minio
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
spec:
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: "Parallel"
  serviceName: pyroscope-dev-minio-svc
  replicas: 1
  selector:
    matchLabels:
      app: minio
      release: pyroscope-dev
  template:
    metadata:
      name: pyroscope-dev-minio
      labels:
        app: minio
        release: pyroscope-dev
      annotations:
        checksum/secrets: 2e760de5dbcac8daf468cd56713bca0aac7d7adc4445e2488b352dbb2b529507
        checksum/config: 925d78a7321daaaa06a6dc4ee47dbaf5b8952be192bdbb57f13805ad472ce4e1
        phlare.grafana.com/port: "9000"
        phlare.grafana.com/scrape: "true"
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch

      serviceAccountName: minio-sa
      containers:
        - name: minio
          image: quay.io/minio/minio:RELEASE.2022-08-13T21-54-44Z
          imagePullPolicy: IfNotPresent

          command: [ "/bin/sh",
            "-ce",
            "/usr/bin/docker-entrypoint.sh minio server  http://pyroscope-dev-minio-{0...0}.pyroscope-dev-minio-svc.default.svc.cluster.local/export-{0...1} -S /etc/minio/certs/ --address :9000 --console-address :9001" ]
          volumeMounts:
            - name: export-0
              mountPath: /export-0
            - name: export-1
              mountPath: /export-1            
          ports:
            - name: http
              containerPort: 9000
            - name: http-console
              containerPort: 9001
          env:
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: pyroscope-dev-minio
                  key: rootUser
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: pyroscope-dev-minio
                  key: rootPassword
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
          resources:
            requests:
              cpu: 100m
              memory: 128Mi      
      volumes:
        - name: minio-user
          secret:
            secretName: pyroscope-dev-minio        
  volumeClaimTemplates:
    - metadata:
        name: export-0
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 5Gi
    - metadata:
        name: export-1
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 5Gi
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pyroscope-dev-compactor
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "compactor"
spec:
  serviceName: pyroscope-dev-compactor-headless
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "compactor"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "compactor"
        name: "compactor"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "compactor"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=compactor"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
              subPath: default
            - name: data
              mountPath: /data-compactor
              subPath: compactor
          resources:
            limits:
              memory: 16Gi
            requests:
              cpu: 1
              memory: 8Gi
      terminationGracePeriodSeconds: 1200
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pyroscope-dev-ingester
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "ingester"
spec:
  serviceName: pyroscope-dev-ingester-headless
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "ingester"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "ingester"
        name: "ingester"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "ingester"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=ingester"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 16Gi
            requests:
              cpu: 1
              memory: 8Gi
      terminationGracePeriodSeconds: 600
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/templates/deployments-statefulsets.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: pyroscope-dev-store-gateway
  namespace: default
  labels:
    helm.sh/chart: pyroscope-1.9.0
    app.kubernetes.io/name: pyroscope
    app.kubernetes.io/instance: pyroscope-dev
    app.kubernetes.io/version: "1.9.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: "store-gateway"
spec:
  serviceName: pyroscope-dev-store-gateway-headless
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: pyroscope
      app.kubernetes.io/instance: pyroscope-dev
      app.kubernetes.io/component: "store-gateway"
  template:
    metadata:
      annotations:
        checksum/config: 4ce0ef1a361a705c68628a76a464151c2d63548bff276335f89aa503bff61710
        profiles.grafana.com/cpu.port_name: http2
        profiles.grafana.com/cpu.scrape: "true"
        profiles.grafana.com/goroutine.port_name: http2
        profiles.grafana.com/goroutine.scrape: "true"
        profiles.grafana.com/memory.port_name: http2
        profiles.grafana.com/memory.scrape: "true"
      labels:
        app.kubernetes.io/name: pyroscope
        app.kubernetes.io/instance: pyroscope-dev
        app.kubernetes.io/component: "store-gateway"
        name: "store-gateway"
    spec:
      serviceAccountName: pyroscope-dev
      securityContext:
        fsGroup: 10001
        runAsNonRoot: true
        runAsUser: 10001
      dnsPolicy: ClusterFirst
      containers:
        - name: "store-gateway"
          securityContext:
            {}
          image: "grafana/pyroscope:1.9.0"
          imagePullPolicy: IfNotPresent
          args:
            - "-target=store-gateway"
            - "-self-profiling.disable-push=true"
            - "-server.http-listen-port=4040"
            - "-memberlist.cluster-label=default-pyroscope-dev"
            - "-memberlist.join=dns+pyroscope-dev-memberlist.default.svc.cluster.local.:7946"
            - "-config.file=/etc/pyroscope/config.yaml"
            - "-runtime-config.file=/etc/pyroscope/overrides/overrides.yaml"
            - "-log.level=debug"
            - "-store-gateway.sharding-ring.replication-factor=3"
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE_FQDN
              value: "default.svc.cluster.local."
          ports:
            - name: http2
              containerPort: 4040
              protocol: TCP
            - name: memberlist
              containerPort: 7946
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /ready
              port: http2
              scheme: HTTP
            initialDelaySeconds: 60
          volumeMounts:
            - name: config
              mountPath: /etc/pyroscope/config.yaml
              subPath: config.yaml
            - name: overrides-config
              mountPath: /etc/pyroscope/overrides/
            - name: data
              mountPath: /data
          resources:
            limits:
              memory: 16Gi
            requests:
              cpu: 1
              memory: 8Gi
      volumes:
        - name: config
          configMap:
            name: pyroscope-dev-config
        - name: overrides-config
          configMap:
            name: pyroscope-dev-overrides-config
        - name: data
          emptyDir: {}
---
# Source: pyroscope/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pyroscope-dev-minio-make-bucket-job
  namespace: "default"
  labels:
    app: minio-make-bucket-job
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: pyroscope-dev
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: pyroscope-dev-minio
            - secret:
                name: pyroscope-dev-minio
      containers:
      - name: minio-mc
        image: "quay.io/minio/mc:RELEASE.2022-08-11T00-30-48Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: pyroscope-dev-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: pyroscope/charts/minio/templates/post-install-create-user-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: pyroscope-dev-minio-make-user-job
  namespace: "default"
  labels:
    app: minio-make-user-job
    chart: minio-4.0.12
    release: pyroscope-dev
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: pyroscope-dev
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: pyroscope-dev-minio
            - secret:
                name: pyroscope-dev-minio
      containers:
      - name: minio-mc
        image: "quay.io/minio/mc:RELEASE.2022-08-11T00-30-48Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/add-user"]
        env:
          - name: MINIO_ENDPOINT
            value: pyroscope-dev-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
